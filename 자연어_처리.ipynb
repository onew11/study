{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObiYlCkDE2xTs0hQUh7Wv9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onew11/study/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4_%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 토큰화"
      ],
      "metadata": {
        "id": "Twl7gA2YmxWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzIksUOklVte",
        "outputId": "280ce190-2db5-4a81-a974-c45248e3ddb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "원문:\n",
            " 해보지 않으면 해낼 수 없다\n",
            "\n",
            "토큰화:\n",
            " ['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from numpy import array\n",
        "\n",
        "# text_to_word_sequence 함수 : 텍스트를 단어(혹은 토큰)의 시퀀스로 변환하는 함수\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        " \n",
        "# 텍스트\n",
        "text = '해보지 않으면 해낼 수 없다'\n",
        " \n",
        "# 해당 텍스트 토큰화 / split과 비슷한 개념\n",
        "result = text_to_word_sequence(text)\n",
        "print(\"\\n원문:\\n\", text)\n",
        "print(\"\\n토큰화:\\n\", result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 빈도수 세기\n",
        "\n",
        "# 전처리하려는 문장\n",
        "docs = ['오늘은 바람이 많이 분다',\n",
        "        '오늘은 동물농장 하는 날이다.'\n",
        "       '인공지능을 활용한 자연어 처리']\n",
        " \n",
        "# 토큰화 함수를 이용해 전처리 하는 과정\n",
        "token = Tokenizer()            # 토큰화 함수 지정\n",
        "token.fit_on_texts(docs)       # 토큰화 함수에 문장 적용\n",
        " \n",
        "# 단어의 빈도수를 계산한 결과를 각 옵션에 맞추어 출력\n",
        "# Tokenizer()의 word_counts 함수는 순서를 기억하는 OrderedDict 클래스를 사용\n",
        "\n",
        "print(\"\\n단어 카운트:\\n\", token.word_counts) \n",
        "\n",
        "# 출력되는 순서는 랜덤 \n",
        "print(\"\\n문장 카운트: \", token.document_count)\n",
        "print(\"\\n각 단어가 몇 개의 문장에 포함되어 있는가:\\n\", token.word_docs)\n",
        "print(\"\\n각 단어에 매겨진 인덱스 값:\\n\",  token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzqCvNsemEnJ",
        "outputId": "87b04feb-46af-477f-c18a-b8d44cca8f3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "단어 카운트:\n",
            " OrderedDict([('오늘은', 2), ('바람이', 1), ('많이', 1), ('분다', 1), ('동물농장', 1), ('하는', 1), ('날이다', 1), ('인공지능을', 1), ('활용한', 1), ('자연어', 1), ('처리', 1)])\n",
            "\n",
            "문장 카운트:  2\n",
            "\n",
            "각 단어가 몇 개의 문장에 포함되어 있는가:\n",
            " defaultdict(<class 'int'>, {'많이': 1, '오늘은': 2, '분다': 1, '바람이': 1, '동물농장': 1, '활용한': 1, '하는': 1, '처리': 1, '날이다': 1, '인공지능을': 1, '자연어': 1})\n",
            "\n",
            "각 단어에 매겨진 인덱스 값:\n",
            " {'오늘은': 1, '바람이': 2, '많이': 3, '분다': 4, '동물농장': 5, '하는': 6, '날이다': 7, '인공지능을': 8, '활용한': 9, '자연어': 10, '처리': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩\n",
        "-> 수많은 0과 하나의 1의 값으로 데이터를 구별하는 인코딩"
      ],
      "metadata": {
        "id": "1yL_4-PFoMzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"오랫동안 꿈꾸는 이는 그 꿈을 닮아간다\"\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJJYYVy1oPiY",
        "outputId": "6b1e8f3c-0c24-4f63-b18e-02b516f3a925"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트를 활용하여 긍정, 부정 예측"
      ],
      "metadata": {
        "id": "lRCO3c4JnDYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장\n",
        "docs = [\"재미있어요.\",\"지루해요\", \"재미있긴 한데 생각보다 지루해요\", \"별로에요\", \"최고에요\"]\n",
        "\n",
        "# 긍정 리뷰는 1, 부정 리뷰는 0으로 클래스를 지정합니다.\n",
        "classes = array([1,0,0,0,1])\n",
        "\n",
        "# 토큰화 \n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPa6jTSTnIDp",
        "outputId": "a608ff30-8237-4b4d-c159-68cb5b77e368"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'지루해요': 1, '재미있어요': 2, '재미있긴': 3, '한데': 4, '생각보다': 5, '별로에요': 6, '최고에요': 7}\n"
          ]
        }
      ]
    }
  ]
}